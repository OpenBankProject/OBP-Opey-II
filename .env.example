# Directory where the endpoint and glossary vector databases are
CHROMADB_DIRECTORY="./src/data/chroma_langchain_db"

# Open Bank Project Config
OBP_BASE_URL="https://apisandbox.openbankproject.com"
OBP_API_VERSION="v5.1.0"

# Whether to use consents as an auth method when making a request to OBP "true" or "false"
# You will need to provide a valid consent in the header of the request, see https://apiexplorer-ii-sandbox.openbankproject.com/operationid/OBPv3.1.0-createConsentImplicit?version=OBPv5.1.0
# if this is false, you will need to set the direct login credentials below
USE_OBP_CONSENTS="false"

# Open Bank Project API directlogin Credentials
OBP_USERNAME="your-obp-username"
OBP_PASSWORD="your-obp-password"
OBP_CONSUMER_KEY="your-obp-consumer-key"

# For testing purpouses, fill out the credentials for a consentor account i.e. API Explorer II
API_EXPLORER_CONSUMER_KEY="your-obp-consumer-key"

## Server Config
# Mode to run server in for hot-reloading
MODE="dev"
PORT=5000
JWT_SIGNING_SECRET="very-very-secret"
# Set the CORS allowed origins to whatever frontends will be communicating with Opey, here is the default localhost and port for API Explorer II
CORS_ALLOWED_ORIGINS='["http://localhost:5173"]'

#Langhain Tracing
LANGCHAIN_TRACING_V2="false"
LANGCHAIN_API_KEY="lsv2_pt_..."
LANGCHAIN_PROJECT="langchain-opey"

# SelfRAG Retriever Config
ENDPOINT_RETRIEVER_BATCH_SIZE=8
ENDPOINT_RETRIEVER_MAX_RETRIES=2
# If there are less than this number of endpoints found for a given retrieval, retry with rewritten question
ENDPOINT_RETRIEVER_RETRY_THRESHOLD=1

# Number of conversation tokens at which we trim the messages and summarize the conversation
CONVERSATION_TOKEN_LIMIT=50000

# If true, this disables the tools allowing Opey to call OBP API, I.e returns it to an "Opey 1 - like" state
# A purely informational agent based on the OBP Resource docs and glossary
DISABLE_OBP_CALLING=true

# Model Config
# Currently supported are "openai", "anthropic", and "ollama"
MODEL_PROVIDER="openai"

OPENAI_SMALL_MODEL="gpt-4o-mini"
OPENAI_MEDIUM_MODEL="gpt-4o"

ANTHROPIC_SMALL_MODEL="claude-3-haiku-20240307"
ANTHROPIC_MEDIUM_MODEL="claude-3-sonnet-20240229"
# It is very possible to set both sizes to the same model, if you do not care about cost
# Also note that the models chosen here will need to support tool calling: https://ollama.com/search?&c=tools
OLLAMA_SMALL_MODEL="llama3.2"
OLLAMA_MEDIUM_MODEL="llama3.2"

# Model API
OPENAI_API_KEY="sk-proj-..."
ANTHROPIC_API_KEY="sk-ant-api03-..."

# Default LLM Config, NOTE that you will need the API key for whatever the model provider is
DEFAULT_LLM_MODEL="gpt-4o"
DEFAULT_LLM_TEMPERATURE=0.5